@article{dar2022analyzing,
  title={Analyzing transformers in embedding space},
  author={Dar, Guy and Geva, Mor and Gupta, Ankit and Berant, Jonathan},
  journal={arXiv preprint arXiv:2209.02535},
  year={2022}
}

@article{elhage2021mathematical,
  title={A mathematical framework for transformer circuits},
  author={Elhage, N and Nanda, N and Olsson, C and Henighan, T and Joseph, N and Mann, B and Askell, A and Bai, Y and Chen, A and Conerly, T and others},
  journal={Transformer Circuits Thread},
  year={2021}
}

@article{chughtai2023toy,
  title={A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations},
  author={Chughtai, Bilal and Chan, Lawrence and Nanda, Neel},
  journal={arXiv preprint arXiv:2302.03025},
  year={2023}
}

@article{nanda2023progress,
  title={Progress measures for grokking via mechanistic interpretability},
  author={Nanda, Neel and Chan, Lawrence and Liberum, Tom and Smith, Jess and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2301.05217},
  year={2023}
}

@article{belrose2023eliciting,
  title={Eliciting Latent Predictions from Transformers with the Tuned Lens},
  author={Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and Ostrovsky, Igor and McKinney, Lev and Biderman, Stella and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2303.08112},
  year={2023}
}

@misc{nostalgebraist2020interpreting,
    howpublished = {\url{https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens}},
    url = {https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens},
    author = {nostalgebraist},
    title={interpreting GPT: the logit lens},
    year = {2020}
}

@article{olah2020zoom,
  author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title = {Zoom In: An Introduction to Circuits},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/zoom-in},
  doi = {10.23915/distill.00024.001}
}

@article{elhage2022superposition,
   title={Toy Models of Superposition},
   author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/toy_model/index.html}
}

@misc{millidge2022singular,
    howpublished = {\url{https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight}},
    url = {https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight},
    author = {Millidge, Beren and Black, Sid},
    title={The Singular Value Decompositions of Transformer Weight Matrices are Highly Interpretable},
    year = {2022}
}

@misc{hubinger2021automating,
    howpublished = {\url{https://www.alignmentforum.org/posts/cQwT8asti3kyA62zc/automating-auditing-an-ambitious-concrete-technical-research}},
    url = {https://www.alignmentforum.org/posts/cQwT8asti3kyA62zc/automating-auditing-an-ambitious-concrete-technical-research},
    author = {Hubinger, Evan},
    title={Automating Auditing: An ambitious concrete technical research proposal},
    year = {2021}
}

@misc{hubinger2019chris,
    howpublished = {\url{https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety}},
    url = {https://www.lesswrong.com/posts/X2i9dQQK3gETCyqh2/chris-olah-s-views-on-agi-safety},
    author = {Hubinger, Evan},
    title={Chris Olahâ€™s views on AGI safety},
    year = {2019}
}

@article{elhage2022solu,
   title={Softmax Linear Units},
   author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Nanda, Neel and Henighan, Tom and Johnston, Scott and ElShowk, Sheer and Joseph, Nicholas and DasSarma, Nova and Mann, Ben and Hernandez, Danny and Askell, Amanda and Ndousse, Kamal and Jones, And  and Drain, Dawn and Chen, Anna and Bai, Yuntao and Ganguli, Deep and Lovitt, Liane and Hatfield-Dodds, Zac and Kernion, Jackson and Conerly, Tom and Kravec, Shauna and Fort, Stanislav and Kadavath, Saurav and Jacobson, Josh and Tran-Johnson, Eli and Kaplan, Jared and Clark, Jack and Brown, Tom and McCandlish, Sam and Amodei, Dario and Olah, Christopher},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/solu/index.html}
}

@inproceedings{hernandez2022natural,
  title={Natural language descriptions of deep visual features},
  author={Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{zhong2022describing,
  title={Describing differences between text distributions with natural language},
  author={Zhong, Ruiqi and Snell, Charlie and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={27099--27116},
  year={2022},
  organization={PMLR}
}

@article{zhong2023goal,
  title={Goal Driven Discovery of Distributional Differences via Language Descriptions},
  author={Zhong, Ruiqi and Zhang, Peter and Li, Steve and Ahn, Jinwoo and Klein, Dan and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2302.14233},
  year={2023}
}

@misc{chan2022causal,
    howpublished = {\url{https://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing}},
    url = {https://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing},
    author = {Chan, Lawrence and Garriga-Alonso, Adria and Goldowsky-Dill, Nicholas and Greenblatt, Ryan and Nitishinskaya, Jenny and Radhakrishnan, Ansh and Shlegeris, Buck and Thomas, Nate},
    title={Causal scrubbing: a method for rigorously testing interpretability hypotheses},
    year = {2022}
}

@article{vig2020causal,
  title={Causal mediation analysis for interpreting neural nlp: The case of gender bias},
  author={Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Sakenis, Simas and Huang, Jason and Singer, Yaron and Shieber, Stuart},
  journal={arXiv preprint arXiv:2004.12265},
  year={2020}
}

@article{singh2022explaining,
  title={Explaining patterns in data with language models via interpretable autoprompting},
  author={Singh, Chandan and Morris, John X and Aneja, Jyoti and Rush, Alexander M and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2210.01848},
  year={2022}
}

@article{meng2022locating,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@inproceedings{donnelly2019interpretability,
  title={On interpretability and feature representations: an analysis of the sentiment neuron},
  author={Donnelly, Jonathan and Roegiest, Adam},
  booktitle={Advances in Information Retrieval: 41st European Conference on IR Research, ECIR 2019, Cologne, Germany, April 14--18, 2019, Proceedings, Part I 41},
  pages={795--802},
  year={2019},
  organization={Springer}
}

@inproceedings{bau2017network,
  title={Network dissection: Quantifying interpretability of deep visual representations},
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6541--6549},
  year={2017}
}

@article{olah2017feature,
  author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  title = {Feature Visualization},
  journal = {Distill},
  year = {2017},
  note = {https://distill.pub/2017/feature-visualization},
  doi = {10.23915/distill.00007}
}

@article{erhan2009visualizing,
  title={Visualizing higher-layer features of a deep network},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={University of Montreal},
  volume={1341},
  number={3},
  pages={1},
  year={2009}
}

@article{yosinski2015understanding,
  title={Understanding neural networks through deep visualization},
  author={Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
  journal={arXiv preprint arXiv:1506.06579},
  year={2015}
}


@article{cammarata2020curve,
  author = {Cammarata, Nick and Goh, Gabriel and Carter, Shan and Schubert, Ludwig and Petrov, Michael and Olah, Chris},
  title = {Curve Detectors},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/circuits/curve-detectors},
  doi = {10.23915/distill.00024.003}
}

@article{bolukbasi2021interpretability,
  title={An interpretability illusion for bert},
  author={Bolukbasi, Tolga and Pearce, Adam and Yuan, Ann and Coenen, Andy and Reif, Emily and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2104.07143},
  year={2021}
}


@misc{millerneo2023anneuron,
    howpublished = {\url{https://clementneo.com/posts/2023/02/11/we-found-an-neuron}},
    url = {https://clementneo.com/posts/2023/02/11/we-found-an-neuron},
    author = {Miller, Joseph and Neo, Clement},
    title={We Found An Neuron in GPT-2},
    year = {2023}
}

@article{oikarinen2022clip,
  title={CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks},
  author={Oikarinen, Tuomas and Weng, Tsui-Wei},
  journal={arXiv preprint arXiv:2204.10965},
  year={2022}
}

@article{openai2023gpt4,
   title={GPT-4 Technical Report},
   author={OpenAI},
   year={2023},
   journal={arXiv preprint arXiv:2303.08774}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{irving2018ai,
  title={AI safety via debate},
  author={Irving, Geoffrey and Christiano, Paul and Amodei, Dario},
  journal={arXiv preprint arXiv:1805.00899},
  year={2018}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{shazeer2020glu,
  title={Glu variants improve transformer},
  author={Shazeer, Noam},
  journal={arXiv preprint arXiv:2002.05202},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{chu2017cyclegan,
  title={Cyclegan, a master of steganography},
  author={Chu, Casey and Zhmoginov, Andrey and Sandler, Mark},
  journal={arXiv preprint arXiv:1712.02950},
  year={2017}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@misc{leike2022ourapproach,
    howpublished = {\url{https://openai.com/blog/our-approach-to-alignment-research}},
    url = {https://openai.com/blog/our-approach-to-alignment-research},
    author = {Leike, Jan and Schulman, John and Wu, Jeffrey},
    title={Our approach to alignment research},
    year = {2022}
}

@inproceedings{subramanian2018spine,
  title={Spine: Sparse interpretable neural embeddings},
  author={Subramanian, Anant and Pruthi, Danish and Jhamtani, Harsh and Berg-Kirkpatrick, Taylor and Hovy, Eduard},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{murphy2012learning,
  title={Learning effective and interpretable semantic models using non-negative sparse embedding},
  author={Murphy, Brian and Talukdar, Partha and Mitchell, Tom},
  booktitle={Proceedings of COLING 2012},
  pages={1933--1950},
  year={2012}
}

@inproceedings{foote2023n2g,
  title={N2G: A Scalable Approach for Quantifying Interpretable Neuron Representations in Large Language Models},
  author={Foote, Alex and Nanda, Neel and Kran, Esben and Konstas, Ioannis and Barez, Fazl},
  booktitle={ICLR 2023 Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models}
}

@article{wang2022interpretability,
  title={Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small},
  author={Wang, Kevin and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2211.00593},
  year={2022}
}

@article{wu2018nonnegative,
  title={Nonnegative matrix factorization with mixed hypergraph regularization for community detection},
  author={Wu, Wenhui and Kwong, Sam and Zhou, Yu and Jia, Yuheng and Gao, Wei},
  journal={Information Sciences},
  volume={435},
  pages={263--281},
  year={2018},
  publisher={Elsevier}
}

@article{olah2018the,
  author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
  title = {The Building Blocks of Interpretability},
  journal = {Distill},
  year = {2018},
  note = {https://distill.pub/2018/building-blocks},
  doi = {10.23915/distill.00010}
}

@article{lee1999learning,
  title={Learning the parts of objects by non-negative matrix factorization},
  author={Lee, Daniel D and Seung, H Sebastian},
  journal={Nature},
  volume={401},
  number={6755},
  pages={788--791},
  year={1999},
  publisher={Nature Publishing Group UK London}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@misc{millidge2022svd,
    howpublished = {\url{https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight}},
    url = {https://www.alignmentforum.org/posts/mkbGjzxD8d8XqKHzA/the-singular-value-decompositions-of-transformer-weight},
    author = {Millidge, Beren and Black, Sid},
    title={The Singular Value Decompositions of Transformer Weight Matrices are Highly Interpretable},
    year = {2022}
}

@misc{sharkey2022taking,
    howpublished = {\url{https://www.alignmentforum.org/posts/z6QQJbtpkEAX3Aojj/interim-research-report-taking-features-out-of-superposition}},
    url = {https://www.alignmentforum.org/posts/z6QQJbtpkEAX3Aojj/interim-research-report-taking-features-out-of-superposition},
    author = {Sharkey, Lee and Braun, Dan and Millidge, Beren},
    title={Taking features out of superposition with sparse autoencoders},
    year = {2022}
}

@article{girvan2002community,
  title={Community structure in social and biological networks},
  author={Girvan, Michelle and Newman, Mark EJ},
  journal={Proceedings of the national academy of sciences},
  volume={99},
  number={12},
  pages={7821--7826},
  year={2002},
  publisher={National Acad Sciences}
}

@article{gauvin2014detecting,
  title={Detecting the community structure and activity patterns of temporal networks: a non-negative tensor factorization approach},
  author={Gauvin, Laetitia and Panisson, Andr{\'e} and Cattuto, Ciro},
  journal={PloS one},
  volume={9},
  number={1},
  pages={e86028},
  year={2014},
  publisher={Public Library of Science San Francisco, USA}
}

@inproceedings{foerster2017input,
  title={Input switched affine networks: An rnn architecture designed for interpretability},
  author={Foerster, Jakob N and Gilmer, Justin and Sohl-Dickstein, Jascha and Chorowski, Jan and Sussillo, David},
  booktitle={International conference on machine learning},
  pages={1136--1145},
  year={2017},
  organization={PMLR}
}

@inproceedings{gonzalez2017re,
  title={Re-training deep neural networks to facilitate Boolean concept extraction},
  author={Gonz{\'a}lez, Camila and Loza Menc{\'\i}a, Eneldo and F{\"u}rnkranz, Johannes},
  booktitle={Discovery Science: 20th International Conference, DS 2017, Kyoto, Japan, October 15--17, 2017, Proceedings 20},
  pages={127--143},
  year={2017},
  organization={Springer}
}

@article{raghu2017svcca,
  title={Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability},
  author={Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@misc{hubinger2021risks,
      title={Risks from Learned Optimization in Advanced Machine Learning Systems}, 
      author={Evan Hubinger and Chris van Merwijk and Vladimir Mikulik and Joar Skalse and Scott Garrabrant},
      year={2021},
      eprint={1906.01820},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{shah2022goal,
      title={Goal Misgeneralization: Why Correct Specifications Aren't Enough For Correct Goals}, 
      author={Rohin Shah and Vikrant Varma and Ramana Kumar and Mary Phuong and Victoria Krakovna and Jonathan Uesato and Zac Kenton},
      year={2022},
      eprint={2210.01790},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ngo2023alignment,
      title={The alignment problem from a deep learning perspective}, 
      author={Richard Ngo and Lawrence Chan and SÃ¶ren Mindermann},
      year={2023},
      eprint={2209.00626},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{carter2019activation,
  title={Activation atlas},
  author={Carter, Shan and Armstrong, Zan and Schubert, Ludwig and Johnson, Ian and Olah, Chris},
  journal={Distill},
  volume={4},
  number={3},
  pages={e15},
  year={2019}
}

@article{tenney2020language,
  title={The language interpretability tool: Extensible, interactive visualizations and analysis for NLP models},
  author={Tenney, Ian and Wexler, James and Bastings, Jasmijn and Bolukbasi, Tolga and Coenen, Andy and Gehrmann, Sebastian and Jiang, Ellen and Pushkarna, Mahima and Radebaugh, Carey and Reif, Emily and others},
  journal={arXiv preprint arXiv:2008.05122},
  year={2020}
}

@article{gurnee2023finding,
  title={Finding Neurons in a Haystack: Case Studies with Sparse Probing},
  author={Gurnee, Wes and Nanda, Neel and Pauly, Matthew and Harvey, Katherine and  Troitskii, Dmitrii and Bertsimas, Dimitris},
  journal={arXiv preprint arXiv:2305.01610},
  year={2023}
}

@misc{neuroscope,
  title = {Neuroscope},
  author={Nanda, Neel},
  howpublished = {\url{https://neuroscope.io/}},
  url = {https://neuroscope.io/},
  note = {Accessed: 2023-05-03}
}

@article{olsson2022context,
   title={In-context Learning and Induction Heads},
   author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@misc{christiano2021elk,
      title={Eliciting latent knowledge: How to tell if your eyes deceive you},
      author={Paul Christiano and Ajeya Cotra and Mark Xu},
      year={2021},
      month={12},
      url={https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8}
}

@article{goodhart1975problems,
  title={Problems of monetary management: the UK experience in papers in monetary economics},
  author={Goodhart, Charles},
  journal={Monetary Economics},
  volume={1},
  year={1975}
}

@misc{gao2022scaling,
      title={Scaling Laws for Reward Model Overoptimization}, 
      author={Leo Gao and John Schulman and Jacob Hilton},
      year={2022},
      eprint={2210.10760},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
